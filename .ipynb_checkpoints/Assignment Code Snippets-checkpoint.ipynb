{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    " vocabulary = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', \n",
    "               'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \n",
    "               '0', '.', ' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1\n",
    "def preprocess_line(line):\n",
    "    # Add markers to beginning and end of sentence\n",
    "    line = '##' + line + '#'\n",
    "    # The regex below defines a character set consisting of only alphabets, digits, spaces, full-stops and the sentence marker\n",
    "    # Remove all unwanted characters that are not part of this character set\n",
    "    # Additionally replace all digits with 0\n",
    "    return re.sub('r\\d', '0', re.sub(r'[^a-zA-Z\\d.\\s#]+', '', line)).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3 a.\n",
    "def generate_trigrams_from_vocabulary():\n",
    "    # We use the '#' character to symbolise both, the beginning i.e., <s> and end i.e., </s> of sentence markers\n",
    "    \n",
    "    # Generate trigrams with the beginning-of-sentence marker i.e., of type <s><s>a\n",
    "    set_of_all_possible_trigrams = ['##' + character for character in vocabulary]\n",
    "    \n",
    "    # Generate all trigrams that are read from the second sentence marker onwards i.e., of type <s>ab\n",
    "    set_of_all_possible_trigrams.extend(['#' + character_one + character_two for character_one in vocabulary for character_two in vocabulary])\n",
    "    \n",
    "    # Generate all trigrams with the end-of-sentence marker i.e. of type ab</s>\n",
    "    set_of_all_possible_trigrams.extend([character_n_minus_one + character_n_minus_two + '#' for character_n_minus_one in vocabulary for character_n_minus_two in vocabulary])\n",
    "    \n",
    "    # Generate all trigrams that occur within the sentence (i.e., without the sentence markers)\n",
    "    set_of_all_possible_trigrams.extend([character_one + character_two + character_three for character_one in vocabulary for character_two in vocabulary for character_three in vocabulary])\n",
    "    \n",
    "    # Return the set of all possible trigrams generated from the given vocabulary\n",
    "    return set_of_all_possible_trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3 b.\n",
    "def count_trigrams(sequence):\n",
    "    distribution_over_next_characters_from_training_data = dict()\n",
    "    for index in range(3, len(sequence)+1):\n",
    "        trigram = sequence[index-3: index]\n",
    "        bigram = trigram[:-1]\n",
    "        next_character = trigram[-1]\n",
    "        if bigram not in distribution_over_next_characters_from_training_data:\n",
    "            distribution_over_next_characters_from_training_data[bigram] = defaultdict()\n",
    "        if next_character not in distribution_over_next_characters_from_training_data[bigram]:\n",
    "            distribution_over_next_characters_from_training_data[bigram][next_character] = 0\n",
    "        distribution_over_next_characters_from_training_data[bigram][next_character] += 1\n",
    "    return distribution_over_next_characters_from_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3 c.\n",
    "def model_trigrams_from_training_data(training_file):\n",
    "    set_of_all_possible_trigrams = generate_trigrams_from_vocabulary()\n",
    "    distribution_over_next_characters_from_vocabulary = dict() \n",
    "    \n",
    "    # Contruct a map with unique bigram histories as keys and a list of all-possible-next-characters as their value-pair (defined as dict within dict model)\n",
    "    for trigram in set_of_all_possible_trigrams:\n",
    "        bigram = trigram[:-1]\n",
    "        next_character = trigram[-1]\n",
    "        if bigram not in distribution_over_next_characters_from_vocabulary:\n",
    "            distribution_over_next_characters_from_vocabulary[bigram] = dict()\n",
    "        if next_character not in distribution_over_next_characters_from_vocabulary[bigram]:\n",
    "            distribution_over_next_characters_from_vocabulary[bigram][next_character] = 0\n",
    "            \n",
    "    # Read the training file and compute all trigram counts\n",
    "    with open(file, 'r') as file:\n",
    "        for line in file:\n",
    "            # Preprocess every line in file\n",
    "            preprocessed_line = preprocess_line(line)\n",
    "            # Generate the trigram counts for each line\n",
    "            distribution_over_next_characters_from_training_data = count_trigrams(preprocessed_line)\n",
    "            # Add these values to distribution_over_next_characters_from_vocabulary\n",
    "            for bigrams in distribution_over_next_characters_from_vocabulary:\n",
    "                for next_character in distribution_over_next_characters_from_vocabulary[bigram]:\n",
    "                    distribution_over_next_characters_from_vocabulary[bigram][next_character] += distribution_over_next_characters_from_training_data[bigram][next_character]\n",
    "    file.close()\n",
    "    \n",
    "    total_bigram_count = 0\n",
    "    vocabulary_size = len(vocabulary)\n",
    "    # Extract the language suffix from the training file (i.e. en, es or de)\n",
    "    # Create a new file to write out the trained model probabilities for each of the above training files\n",
    "    trigram_model = '{}_trained_trigram_model'.format(training_file[-2:])\n",
    "    \n",
    "    # Compute the probability distributions over the trigrams in the training data and write them out to a file\n",
    "    with open(trigram_model, 'w+') as file:\n",
    "        for bigram in distribution_over_next_characters_from_vocabulary:\n",
    "            # Calculate the total number of trigram instances with the same bigram history\n",
    "            total_bigram_count += sum(distribution_over_next_characters_from_vocabulary[bigram].values())\n",
    "            for next_character in distribution_over_next_characters_from_vocabulary[bigram]:\n",
    "                # For each bigram in the vocabulary, perform add alpha smoothing over the next possible trigram character\n",
    "                distribution_over_next_characters_from_vocabulary[bigram][next_character] += smoothing_constant_alpha\n",
    "                distribution_over_next_characters_from_vocabulary[bigram][next_character] /= (total_bigram_count + (smoothing_constant_alpha * vocabulary_size))\n",
    "                trigram_model.write(bigram + next_character + '\\t' + \"{:.3e}\".format(distribution_over_next_characters_from_vocabulary[bigram][next_character]) + '\\n')\n",
    "    trigram_model.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4 a.\n",
    "def generate_from_LM(language_model, n_characters):\n",
    "    lm_trigram_probabilities = dict()\n",
    "    \n",
    "    # Read the language model\n",
    "    with open(language_model, 'r') as file:\n",
    "        for line in file:\n",
    "            # Split the line to extract the trigram and its probability, respectively\n",
    "            trigram_and_its_probability = line.split('\\t')\n",
    "            \n",
    "            # Unwrap the contents of the list trigram_and_its_probability\n",
    "            trigram = trigram_and_its_probability[0]\n",
    "            trigram_probability = float(trigram_and_its_probability[1])\n",
    "            \n",
    "            # Extract the bigram history and next character for each trigram that's read from the language model\n",
    "            bigram_history = trigram[:-1]\n",
    "            next_character = trigram[-1]\n",
    "            \n",
    "            # Store the probabilties for each trigram in a dictionary (using the same dict within dict format as before)\n",
    "            if bigram_history not in lm_trigram_probabilities:\n",
    "                lm_trigram_probabilities[bigram_history] = dict()\n",
    "            if next_character not in lm_trigram_probabilities[bigram_history]:\n",
    "                lm_trigram_probabilities[bigram_history][next_character] = trigram_probability\n",
    "\n",
    "    file.close()\n",
    "    \n",
    "    bigram_history_lookup = '##'\n",
    "    generated_sequence = '##'\n",
    "    \n",
    "    for num_characters in range(n_characters):\n",
    "        # Randomly samples the next character of the trigram sequence, given the bigram history and probability distribution over the trigram vocabulary\n",
    "        distribution = lm_trigram_probabilities[bigram_history_lookup]\n",
    "        all_possible_characters = np.array(list(distribution.keys()))\n",
    "        probablity_distribution = np.array(list(distribution.values()))\n",
    "        bins = np.cumsum(probablity_distribution)\n",
    "        chosen_next_character = ''.join(map(str, all_possible_characters[np.digitize(np.random.random_sample(1), bins)]))\n",
    "        if chosen_next_character == '#':\n",
    "            bigram_history_lookup = '##'\n",
    "        else:\n",
    "            bigram_history_lookup = bigram_history_lookup[1] + chosen_next_character\n",
    "        generated_sequence += chosen_next_character\n",
    "        num_characters += 1\n",
    "    \n",
    "    return generated_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4 b.\n",
    "def write_generated_sequence_to_file(sequence, language_model):\n",
    "    with open ('{}_generated_sequence'.format(language_model), 'w+') as file:\n",
    "        for character in sequence:\n",
    "            if character == '#':\n",
    "                continue\n",
    "            file.write(character)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5 - To Do\n",
    "def compute_perplexity(hm):\n",
    "    # TBC\n",
    "    return math.pow(2, hm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/afs/inf.ed.ac.uk/user/s24/s2446690/Desktop/anlp/assignment1/data/training.es', '/afs/inf.ed.ac.uk/user/s24/s2446690/Desktop/anlp/assignment1/data/training.en', '/afs/inf.ed.ac.uk/user/s24/s2446690/Desktop/anlp/assignment1/data/training.de']\n"
     ]
    }
   ],
   "source": [
    "# To Do\n",
    "data_directory = os.path.join(os.getcwd(), 'data')\n",
    "training_files = []\n",
    "\n",
    "'''\n",
    "Iterates through the current directory to fetch all training files i.e training.de, training.en, training.es\n",
    "Stores the absolute path of these files in the training_files list\n",
    "'''\n",
    "[training_files.append(data_directory + '/' + training_file) for training_file in os.listdir(data_directory) if training_file.startswith('training')]\n",
    "\n",
    "# Print the file paths\n",
    "print(training_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
